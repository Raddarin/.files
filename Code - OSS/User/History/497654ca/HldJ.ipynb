{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inledning\n",
    "## Importera Moduler\n",
    "Först importerar vi lämpliga moduler som behövs i analysen. Det är numpy, scipy och pandas för grundläggande datahantering och statistik; matplotlib och seaborn för plottning samt statsmodels för regressionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#För att installera moduleran först avkommentera följande rad\n",
    "#%pip install numpy scipy pandas matplotlib seaborn statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Läs in data\n",
    "Ladda ner datafilen från canvas sidan och lägga csv-filen i samma katalog som ditt Python script, eller ange en lämplig relativ sökväg. Se laborationern för hur vi hanterade data. \n",
    "\n",
    "Vi skriver också ut data för att få en översikt av variablerna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fisk = pd.read_csv('fisk.csv', encoding='utf-8')\n",
    "print( fisk )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan också gör en describe på data materialet (include='all' ser till att även Art so är en text variabel kommer med)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( fisk.describe(include='all') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För Art variabeln kan det vara intressant med antalet olika arter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fisk.Art.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotta data\n",
    "Vi kan nu illustrera data. Vi börjar med **Vikt** som funktion av **Langd** och färglägger med Art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(fisk, x='Langd', y='Vikt', hue='Art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan också plotta med logaritmisk y-axel (eller x-axel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(fisk, x='Langd', y='Vikt', hue='Art')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dela data in träning och test\n",
    "För att dela data i träning och utvärdering så använder vi **sample** funktionen i pandas för att slumpmässigt välja 80% av observationerna. Sen använder vi **drop** för att konstruera ett utvärderingsset som **inte** innehåller träningsdata. Notera att **sample** har en extra parameter **random_state** som kan användas för att bestämma vilka slumptal som ska användas så att tränningsdata alltid blir samma när man kör koden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisk_train = fisk.sample(frac=0.8, random_state=1) ##Använd ert grupp-nummer som random_state\n",
    "fisk_test = fisk.drop(fisk_train.index)\n",
    "print( fisk_train.describe(include='all') )\n",
    "print( fisk_test.describe(include='all') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inledande enkel regression\n",
    "Det finns minst två sätt att göra regression i python funktioner från scikit-learn som använder matris formerna direkt och kräver att användaren konstruera X matrisen för hand\n",
    "**sklearn.linear_model.LinearRegression()**. Ett bättre alternativ är statsmodels regressions funktioner som direkt omvandlar formler till lämpliga X och Y matriser.\n",
    "**statsmodels.formula.api.ols()**. \n",
    "\n",
    "Vi kommer nu använda **statsmodels** för att demonstrerar en enkel regression där **Vikt** enbart förklaras av **Langd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help( smf.ols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = smf.ols(formula='Vikt ~ Langd', data=fisk_train)\n",
    "print( res.fit().summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notera att **smf.ols** själv lägger till ett intercept så *Vikt ~ Langd* ger modellen \n",
    "\n",
    "$Vikt_i = \\beta_0 + \\beta_1 Langd_i + \\epsilon_i$\n",
    "\n",
    "För att anpassa en modell utan $\\beta_0$ kan vi använda *Vikt ~ Langd+0* eller *Vikt ~ Langd-1*.\n",
    "\n",
    "Resultaten innehåller skattade parametrar och deras osäkerheter. Andra halvan är en utvärdering av om residualerna är normalfördelade. För normalfördelade residualer bör vi ha\n",
    "* Prob(Omnibus) > 0.05\n",
    "* Skew=0\n",
    "* Kurtosis=3\n",
    "* Prob(JB) > 0.05 \n",
    "\n",
    "Här är Python anningen pettig; regressionen fungerar rimligt bra även för mindre avvikelser från normalfördelade residualer. Vill vi trasformera y eller x värden kan transformen tas med i formlen, tänk på att de flesta relevanta funktioner finns i numpy. Exempel\n",
    "* *formula = np.log(Vikt) ~ Langd* för log-transformation av vikten\n",
    "* *formula = Vikt ~ Langd + I(Langd**2)* för ett andragrads polynom av längden\n",
    "\n",
    "### Regresion resultat\n",
    "Vi vill nu analysera resultatet av regressionen. De anpassade variablerna finns i *res.fit().params*, och kan användas för att illustrerar anpassningen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = res.fit().params\n",
    "sns.scatterplot(fisk_train, x='Langd', y='Vikt', hue='Art')\n",
    "#hämta under gräns för x initial punkt för linjen.\n",
    "x_min = plt.gca().get_xlim()[0]\n",
    "plt.axline((x_min,beta.Intercept+x_min*beta.Langd),slope=beta.Langd) #start punkt (x_min,intercept+x_min*beta_1) och lutning slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisk_train['Langd3'] = fisk_train['Langd']**3\n",
    "\n",
    "res = smf.ols(formula='Vikt ~ Langd3', data=fisk_train).fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan nu plocka ut lite olika värden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skattade parameterar\n",
    "res.fit().params\n",
    "#konfidens intervall för parametrarna\n",
    "res.fit().conf_int()\n",
    "#Kovariansmatris för parametrarna\n",
    "res.fit().cov_params()\n",
    "#anpassade värden\n",
    "yhat = res.fit().fittedvalues\n",
    "#residualer\n",
    "epsilon = res.fit().resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ett alternativ är att studera hur residualerna och anpassade värden relaterar till resten av data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisk_train['residualer'] = res.fit().resid\n",
    "fisk_train['yhat'] = res.fit().fittedvalues\n",
    "\n",
    "sns.scatterplot(fisk_train, x='yhat', y='Vikt', hue='Art')\n",
    "#hämta under gräns för x och y och använd största av dessa som initial punkt för linjen.\n",
    "xy_min = np.max((plt.gca().get_xlim()[0],plt.gca().get_ylim()[0]))\n",
    "plt.axline((xy_min,xy_min),slope=1,color='red') #y=x referens linje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(fisk_train, x='residualer', stat='density', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot = stats.probplot(fisk_train.residualer, dist=\"norm\", fit=True, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(fisk_train, x='yhat', y='Vikt', lowess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(fisk_train, y_vars='residualer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För att jämföra med utvärderings data så använder vi först modellen för att prediktera vikterna och addera det som en kolumn i *fisk_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisk_test['yhat'] = res.fit().predict(fisk_test)\n",
    "#scatter plot\n",
    "sns.scatterplot(fisk_test, x='yhat', y='Vikt', hue='Art')\n",
    "xy_min = np.max((plt.gca().get_xlim()[0],plt.gca().get_ylim()[0]))\n",
    "plt.axline((xy_min,xy_min),slope=1,color='red')\n",
    "#MSE\n",
    "print( np.mean( (fisk_test.Vikt - fisk_test.yhat)**2 ) )\n",
    "#samma plotar som ovan kan användas även för utvärderingsdatan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformerade y-variabler\n",
    "Om Y variabeln transformeras kan vi inte längre bra rita en rak linje utan behöver prediktera värden som vi kan addera till ploten. Först skappar vi en data frame med prediktions värden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_G = pd.DataFrame({'Art': fisk_train.Art.unique()[0],\n",
    "                       'Langd': np.arange(min(fisk_train.Langd),max(fisk_train.Langd)+1)})\n",
    "Pred_R = pd.DataFrame({'Art': fisk_train.Art.unique()[1],\n",
    "                       'Langd': np.arange(min(fisk_train.Langd),max(fisk_train.Langd)+1)})\n",
    "#gemensam data.frame för alla prediktioner\n",
    "Pred = pd.concat( [Pred_G,Pred_R] )\n",
    "#titta på data\n",
    "print(Pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan nu göra en regression och prediktera för alla värden i **Pred** och använda dessa för att rita in anpassningen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression\n",
    "res_logV = smf.ols(formula='np.log(Vikt) ~ Langd', data=fisk_train)\n",
    "print( res_logV.fit().summary() )\n",
    "#prediktion, kom ihåg att transformera tillbaka\n",
    "Pred['yhat'] = np.exp( res_logV.fit().predict(Pred) )\n",
    "\n",
    "sns.scatterplot(fisk_train, x='Langd', y='Vikt', hue='Art')\n",
    "sns.lineplot(Pred, x='Langd', y='yhat', hue='Art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativt kan vi plotta med logaritmisk y-axel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediktion, i log-skala\n",
    "sns.scatterplot(fisk_train, x='Langd', y='Vikt', hue='Art')\n",
    "sns.lineplot(Pred, x='Langd', y='yhat', hue='Art')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För residual analysen måste vi komma ihåg att det är residualerna från\n",
    "\n",
    "$\\log(Vikt_i) = \\beta_0 + \\beta_1 Langd_i + \\epsilon_i$\n",
    "\n",
    "som ska vara normalfördelade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression residualer och anpassade värden (log(Vikt)-skala) från res\n",
    "fisk_train['residualer_logV'] = res_logV.fit().resid\n",
    "fisk_train['yhat_logV'] = res_logV.fit().fittedvalues\n",
    "\n",
    "##subplots\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "#prediktioner mot värden\n",
    "sns.scatterplot(fisk_train, x='yhat_logV', y=np.log(fisk_train.Vikt), hue='Art', ax=axs[0])\n",
    "xy_min = min( (axs[0].get_xlim()[0], axs[0].get_ylim()[0]) )\n",
    "axs[0].axline((xy_min,xy_min),slope=1)\n",
    "##qqplot\n",
    "qqplot = stats.probplot(fisk_train.residualer_logV, dist=\"norm\", fit=True, plot=axs[1])\n",
    "\n",
    "#eller för hand\n",
    "epsilon = np.log(fisk_train.Vikt) - res_logV.fit().fittedvalues\n",
    "#vilket ger samma resultat\n",
    "print(epsilon-fisk_train['residualer_logV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips för projektet\n",
    "1. Gör ett rimligt modelval och skatta modellen, anpassa koden ovan för model utvärdering. Mer komplicerade formler ger olika lutning eller intercept mellan arterna. Alternativ att fundera på är:\n",
    "    * *Y ~ A + B*     ger modellen $Y_i = \\beta_0 + \\beta_1 \\cdot A_i + \\beta_2 \\cdot B_i + \\epsilon_i$\n",
    "    * *Y ~ A\\*B*       ger modellen $Y_i = \\beta_0 + \\beta_1 \\cdot A_i + \\beta_2 \\cdot B_i + \\beta_3 \\cdot (A_i \\cdot B_i) + \\epsilon_i$\n",
    "    * *Y ~ A:B*       ger modellen $Y_i = \\beta_0 + \\beta_1 \\cdot (A_i \\cdot B_i) + \\epsilon_i$\n",
    "2. Undersök de skattade parametrarna och tolka dessa\n",
    "3. För prediktion så behöver ni först konstruera en *DataFrame* som innehåller data som ni vill prediktera för:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_0 = pd.DataFrame({'Art' : [?, ?],\n",
    "                    'Langd' : [?, ?]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Givet en ny DataFrame kan prediktions funktionerna användas för att få punkt-prediktioner, varianser och intervall. Fundera på vilken typ av prediktioner som är lämpligast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.fit().predict(U_0)\n",
    "#Konfidens eller prediktionsintervall, titta i hjälp-texten för vad obs och alpha gör.\n",
    "res.fit().get_prediction(U_0).conf_int(obs=True/False, alpha=?)\n",
    "#Allting på en gång\n",
    "res.fit().get_prediction(U_0).summary_frame(alpha=?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Residual variansen i regressionen, $\\sigma^2$, fås ur *res.fit().scale*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmsf80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
